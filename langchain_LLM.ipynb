{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558d3b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.8-py3-none-any.whl (816 kB)\n",
      "     ------------------------------------- 816.1/816.1 kB 50.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from langchain) (6.0)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Collecting pydantic<3,>=1\n",
      "  Downloading pydantic-2.6.1-py3-none-any.whl (394 kB)\n",
      "     ------------------------------------- 394.8/394.8 kB 33.5 kB/s eta 0:00:00\n",
      "Collecting langchain-core<0.2,>=0.1.24\n",
      "  Downloading langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
      "     ------------------------------------- 241.3/241.3 kB 45.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from langchain) (1.21.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
      "Collecting tenacity<9.0.0,>=8.1.0\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Downloading aiohttp-3.9.3-cp39-cp39-win_amd64.whl (366 kB)\n",
      "     ------------------------------------- 366.0/366.0 kB 40.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from langchain) (2.28.1)\n",
      "Collecting jsonpatch<2.0,>=1.33\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from langchain) (1.4.39)\n",
      "Collecting langsmith<0.2.0,>=0.1.0\n",
      "  Downloading langsmith-0.1.3-py3-none-any.whl (60 kB)\n",
      "     --------------------------------------- 61.0/61.0 kB 95.6 kB/s eta 0:00:00\n",
      "Collecting langchain-community<0.1,>=0.0.21\n",
      "  Downloading langchain_community-0.0.21-py3-none-any.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 42.7 kB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "     --------------------------------------- 50.7/50.7 kB 46.2 kB/s eta 0:00:00\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (21.4.0)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "     --------------------------------------- 76.9/76.9 kB 68.9 kB/s eta 0:00:00\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "     --------------------------------------- 49.4/49.4 kB 67.8 kB/s eta 0:00:00\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting jsonpointer>=1.9\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: anyio<5,>=3 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from langchain-core<0.2,>=0.1.24->langchain) (3.5.0)\n",
      "Collecting packaging<24.0,>=23.2\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "     --------------------------------------- 53.0/53.0 kB 85.5 kB/s eta 0:00:00\n",
      "Collecting pydantic-core==2.16.2\n",
      "  Downloading pydantic_core-2.16.2-cp39-none-win_amd64.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 32.9 kB/s eta 0:00:00\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2022.9.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (1.26.11)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain) (1.2.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "Installing collected packages: typing-extensions, tenacity, packaging, multidict, jsonpointer, frozenlist, async-timeout, annotated-types, yarl, typing-inspect, pydantic-core, marshmallow, jsonpatch, aiosignal, pydantic, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.3.0\n",
      "    Uninstalling typing_extensions-4.3.0:\n",
      "      Successfully uninstalled typing_extensions-4.3.0\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 8.0.1\n",
      "    Uninstalling tenacity-8.0.1:\n",
      "      Successfully uninstalled tenacity-8.0.1\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.3\n",
      "    Uninstalling packaging-21.3:\n",
      "      Successfully uninstalled packaging-21.3\n",
      "Successfully installed aiohttp-3.9.3 aiosignal-1.3.1 annotated-types-0.6.0 async-timeout-4.0.3 dataclasses-json-0.6.4 frozenlist-1.4.1 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.8 langchain-community-0.0.21 langchain-core-0.1.24 langsmith-0.1.3 marshmallow-3.20.2 multidict-6.0.5 packaging-23.2 pydantic-2.6.1 pydantic-core-2.16.2 tenacity-8.2.3 typing-extensions-4.9.0 typing-inspect-0.9.0 yarl-1.9.4\n",
      "Collecting openai\n",
      "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "     ------------------------------------- 226.7/226.7 kB 13.5 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from openai) (2.6.1)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "     --------------------------------------- 75.9/75.9 kB 24.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: sniffio in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from openai) (3.5.0)\n",
      "Collecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.3)\n",
      "Requirement already satisfied: certifi in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2022.9.14)\n",
      "Collecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.3-py3-none-any.whl (77 kB)\n",
      "     --------------------------------------- 77.0/77.0 kB 44.1 kB/s eta 0:00:00\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "     --------------------------------------- 58.3/58.3 kB 53.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from tqdm>4->openai) (0.4.5)\n",
      "Installing collected packages: h11, distro, httpcore, httpx, openai\n",
      "Successfully installed distro-1.9.0 h11-0.14.0 httpcore-1.0.3 httpx-0.26.0 openai-1.12.0\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     ------------------------------------- 232.6/232.6 kB 19.3 kB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from PyPDF2) (4.9.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp39-cp39-win_amd64.whl (10.8 MB)\n",
      "     --------------------------------------- 10.8/10.8 MB 77.1 kB/s eta 0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.7.4\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp39-cp39-win_amd64.whl (798 kB)\n",
      "     ------------------------------------- 798.7/798.7 kB 97.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from tiktoken) (2.28.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.3)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2022.9.14)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kaosh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->tiktoken) (1.26.11)\n",
      "Installing collected packages: tiktoken\n",
      "Successfully installed tiktoken-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain\n",
    "!pip install openai\n",
    "!pip install PyPDF2\n",
    "!pip install faiss-cpu\n",
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c6c9707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import ElasticVectorSearch, Pinecone, Weaviate, FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79028a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get your API keys from openai, you will need to create an account. \n",
    "# Here is the link to get the keys: https://platform.openai.com/account/billing/overview\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b4321a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9828\\1087182101.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# connect your Google Drive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/content/gdrive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mroot_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/content/gdrive/My Drive/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "# connect your Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n",
    "root_dir = \"/content/gdrive/My Drive/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e645f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of the pdf file/files. \n",
    "reader = PdfReader('/content/gdrive/My Drive/data/2023_GPT4All_Technical_Report.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5155375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a96a60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8185d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split the text that we read into smaller chunks so that during information retreival we don't hit the token size limits. \n",
    "\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200,\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28da48",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e6371d",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa1d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download embeddings from OpenAI\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27afb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.from_texts(texts, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe1fa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2118a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_qa_chain(OpenAI(), chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d70772",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"who are the authors of the article?\"\n",
    "docs = docsearch.similarity_search(query)\n",
    "chain.run(input_documents=docs, question=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7085db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
